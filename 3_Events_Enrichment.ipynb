{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Enriching Filtered Events"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll enrich the filtered events from the previous notebook with additional information. We'll use a combination of techniques to enrich the events:\n",
    "\n",
    "1. Topic modeling using a Large Language Model (LLM) to extract topics from the posts\n",
    "2. Creating embeddings for semantic search using a transformer model\n",
    "3. Storing the enriched events in Redis for querying\n",
    "\n",
    "\n",
    "\n",
    "Embeddings are vector representations of text that capture semantic meaning. They allow us to perform semantic search, which is a search based on meaning rather than exact keyword matching. In this notebook, we'll create embeddings for posts and store them in Redis for later querying.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recreating helping functions"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:05:29.433330Z",
     "start_time": "2025-05-18T16:05:29.296077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"redis.clients:jedis:6.0.0\")\n",
    "%use coroutines"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:06:14.710864Z",
     "start_time": "2025-05-18T16:06:14.421406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.resps.StreamEntry\n",
    "import redis.clients.jedis.search.Document\n",
    "\n",
    "data class Event(\n",
    "    val did: String,\n",
    "    val rkey: String,\n",
    "    val text: String,\n",
    "    val timeUs: String,\n",
    "    val operation: String,\n",
    "    val uri: String,\n",
    "    val parentUri: String,\n",
    "    val rootUri: String,\n",
    "    val langs: List<String>,\n",
    "    val similarityScore: Double\n",
    ") {\n",
    "    companion object {\n",
    "        fun fromMap(entry: StreamEntry): Event {\n",
    "            return fromMap(entry.fields)\n",
    "        }\n",
    "\n",
    "        fun fromMap(document: Document): Event {\n",
    "            val fields = document.properties.associate { entry ->  entry.key to entry.value.toString()}\n",
    "            return fromMap(fields)\n",
    "        }\n",
    "\n",
    "        fun fromMap(fields: Map<String, String>): Event {\n",
    "            return Event(\n",
    "                did = fields[\"did\"] ?: \"\",\n",
    "                rkey = fields[\"rkey\"] ?: \"\",\n",
    "                text = fields[\"text\"] ?: \"\",\n",
    "                timeUs = fields[\"timeUs\"] ?: \"\",\n",
    "                operation = fields[\"operation\"] ?: \"\",\n",
    "                uri = fields[\"uri\"] ?: \"\",\n",
    "                parentUri = fields[\"parentUri\"] ?: \"\",\n",
    "                rootUri = fields[\"rootUri\"] ?: \"\",\n",
    "                langs = fields[\"langs\"]?.replace(\"[\", \"\")?.replace(\"]\", \"\")?.split(\", \") ?: emptyList(),\n",
    "                similarityScore = fields[\"similarityScore\"]?.toDouble() ?: 0.0\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:06:17.005894Z",
     "start_time": "2025-05-18T16:06:16.601251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.XReadGroupParams\n",
    "import redis.clients.jedis.StreamEntryID\n",
    "import kotlinx.coroutines.*\n",
    "import redis.clients.jedis.JedisPooled\n",
    "import redis.clients.jedis.bloom.BFReserveParams\n",
    "import redis.clients.jedis.exceptions.JedisDataException\n",
    "import redis.clients.jedis.Connection\n",
    "import redis.clients.jedis.JedisPool\n",
    "import redis.clients.jedis.Transaction\n",
    "\n",
    "val jedis = JedisPooled()\n",
    "\n",
    "fun createConsumerGroup(streamName: String, consumerGroupName: String) {\n",
    "    try {\n",
    "        jedis.xgroupCreate(streamName, consumerGroupName, StreamEntryID(\"0-0\"), true)\n",
    "    } catch (e: Exception) {\n",
    "        println(\"Group already exists\")\n",
    "    }\n",
    "}\n",
    "\n",
    "fun readFromStream(streamName: String, consumerGroup: String, consumer: String, count: Int): List<Map.Entry<String, List<StreamEntry>>> {\n",
    "    return jedis.xreadGroup(\n",
    "        consumerGroup,\n",
    "        consumer,\n",
    "        XReadGroupParams().count(count).block(1),\n",
    "        mapOf(\n",
    "            streamName to StreamEntryID.XREADGROUP_UNDELIVERED_ENTRY\n",
    "        )\n",
    "    ) ?: emptyList()\n",
    "}\n",
    "\n",
    "fun consumeStream(\n",
    "    streamName: String,\n",
    "    consumerGroup: String,\n",
    "    consumer: String,\n",
    "    handlers: List<(Event) -> Pair<Boolean, String>>,\n",
    "    ackFunction: ((String, String, StreamEntry) -> Unit),\n",
    "    count: Int = 5,\n",
    "    limit: Int = 5\n",
    ") {\n",
    "    var lastMessageTime = System.currentTimeMillis()\n",
    "    var consumed = 0\n",
    "\n",
    "    while (consumed < limit) {\n",
    "        val entries = readFromStream(streamName, consumerGroup, consumer, count)\n",
    "        val allEntries = entries.flatMap { it.value }\n",
    "        allEntries.map { entry ->\n",
    "            consumed++\n",
    "            val event = Event.fromMap(entry)\n",
    "\n",
    "            for (handler in handlers) {\n",
    "                val (shouldContinue, message) = handler(event)\n",
    "                ackFunction(streamName, consumerGroup, entry)\n",
    "\n",
    "                if (!shouldContinue) {\n",
    "                    println(\"$consumer: Handler stopped processing: $message\")\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (allEntries.isEmpty()) {\n",
    "            val now = System.currentTimeMillis()\n",
    "            if (now - lastMessageTime >= 2_000) {\n",
    "                println(\"$consumer: No new messages for 2 seconds. Stopping.\")\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "val printUri: (Event) -> Pair<Boolean, String> = {\n",
    "    println(\"Got event from ${it.uri}\")\n",
    "    Pair(true, \"OK\")\n",
    "}\n",
    "\n",
    "fun createBloomFilter(name: String) {\n",
    "    runCatching {\n",
    "        jedis.bfReserve(name, 0.01, 1_000_000L, BFReserveParams().expansion(2))\n",
    "    }.onFailure {\n",
    "        println(\"Bloom filter already exists\")\n",
    "    }\n",
    "}\n",
    "\n",
    "fun deduplicate(bloomFilter: String): (Event) -> Pair<Boolean, String> {\n",
    "    return { event ->\n",
    "        if (jedis.bfExists(bloomFilter, event.uri)) {\n",
    "            Pair(false, \"${event.uri} already processed\")\n",
    "        } else {\n",
    "            Pair(true, \"OK\")\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "val jedisPool = JedisPool()\n",
    "\n",
    "fun ackAndBfFn(bloomFilter: String):  (String, String, StreamEntry) -> Unit = { streamName, consumerGroup, entry ->\n",
    "    jedisPool.resource.use { jedis ->\n",
    "        // Create a transaction\n",
    "        val multi = jedis.multi()\n",
    "\n",
    "        // Acknowledge the message\n",
    "        multi.xack(\n",
    "            streamName,\n",
    "            consumerGroup,\n",
    "            entry.id\n",
    "        )\n",
    "\n",
    "        // Add the URI to the bloom filter\n",
    "        multi.bfAdd(bloomFilter, Event.fromMap(entry).uri)\n",
    "\n",
    "        // Execute the transaction\n",
    "        multi.exec()\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Topic Modeling with Large Language Models\n",
    "Topic modeling is a technique used to discover abstract topics in a collection of documents. In this notebook, we'll use a Large Language Model to extract topics from posts. This will allow us to categorize posts and make them more searchable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Ollama API Client\n",
    "We'll use the Spring AI Ollama client to interact with the Ollama API.\n",
    "\n",
    "Ollama is a tool that allows us to run large language models locally."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:06:11.068203Z",
     "start_time": "2025-05-18T14:06:10.621477Z"
    }
   },
   "cell_type": "code",
   "source": "@file:DependsOn(\"org.springframework.ai:spring-ai-ollama:1.0.0-RC1\")",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The prompt we'll use for the LLM is designed to extract software-related topics from posts. The prompt includes examples of how to format the output and what types of topics to include."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:06:12.225956Z",
     "start_time": "2025-05-18T14:06:12.175045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val systemPrompt = \"\"\"\n",
    "You are a topic classifier specialized in software engineering. Given a post, extract only software-related topics—both explicitly mentioned and reasonably implied.\n",
    "\n",
    "If a post mentions a tool, language, or library, infer related technologies or domains. For example, if the post mentions LangChain, you may infer topics like “Python”, “AI\n",
    "”, and “Machine Learning”. Avoid generic terms like “announcement”, “event”, or “release”. Only return the technical topics. Also avoid too narrow topics such as a specific method or command.\n",
    "\n",
    "If the topic or a very similar is already in the provided list of existing topics, use the one from the list, otherwise, feel free to create a new one.\n",
    "\n",
    "Format your response as comma separated values (ALWAYS, I MEAN IT):\n",
    "\"topic1, topic2, topic3\"\n",
    "\n",
    "Examples:\n",
    "\n",
    "Post:\n",
    "Kotlin is the best programming language for beginners\n",
    "Output:\n",
    "\"Kotlin, Programming Languages\"\n",
    "\n",
    "Post:\n",
    "Excited to try some Hugging Face Models with DJL!\n",
    "Output:\n",
    "\"Hugging Face, Deep Java Library (DJL), Machine Learning, AI, Python, Java\"\n",
    "\n",
    "Post:\n",
    "Just deployed a FastAPI app using Redis as a cache layer\n",
    "Output:\n",
    "\"FastAPI, Redis, Python, Web Development, Caching\"\n",
    "\n",
    "Post:\n",
    "The new version of LangChain is now available!! It’s finally GA!\n",
    "Output:\n",
    "\"LangChain, Python, AI, Machine Learning\"\n",
    "\n",
    "Post:\n",
    "Redis is so cool! I love the LOLWUT command.\n",
    "Output:\n",
    "\"Redis, Database\"\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the Ollama Chat Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:06:15.251357Z",
     "start_time": "2025-05-18T14:06:14.865861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.ollama.OllamaChatModel\n",
    "import org.springframework.ai.ollama.api.OllamaApi\n",
    "import org.springframework.ai.ollama.api.OllamaApi.ChatRequest\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message.Role\n",
    "import org.springframework.ai.ollama.api.OllamaOptions\n",
    "\n",
    "val ollamaApi = OllamaApi.builder()\n",
    "    .baseUrl(\"http://localhost:11434\")\n",
    "    .build()\n",
    "\n",
    "val ollamaOptions = OllamaOptions.builder().model(\"deepseek-coder-v2\").build()\n",
    "\n",
    "val ollamaChatModel = OllamaChatModel.builder()\n",
    "    .ollamaApi(ollamaApi)\n",
    "    .defaultOptions(ollamaOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Modeling Function\n",
    "This function takes a post as input and uses the Ollama API to extract topics from the post. The function returns a string of comma-separated topics."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:06:18.340212Z",
     "start_time": "2025-05-18T14:06:18.183624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.SystemMessage\n",
    "import org.springframework.ai.chat.messages.UserMessage\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "\n",
    "fun topicModeling(post: String, existingTopics: String): String {\n",
    "    // Build a chat message\n",
    "    val messages = listOf(\n",
    "        SystemMessage(systemPrompt),\n",
    "        UserMessage(\"Existing topics: $existingTopics\"),\n",
    "        UserMessage(\"Post: $post\")\n",
    "    )\n",
    "\n",
    "    val response = ollamaChatModel.call(Prompt(messages))\n",
    "    return response.result.output.text\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:18:25.623417Z",
     "start_time": "2025-05-18T15:18:25.011117Z"
    }
   },
   "cell_type": "code",
   "source": "topicModeling(\"Kotlin is the best programming languagues for beginners.\", \"Java, Python, Machine Learning\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " \"Kotlin, Programming Languages\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Talking about Count-min Sketch"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Count-min sketch is a probabilistic data structure used for estimating the frequency of events in a stream of data.\n",
    "\n",
    "It is particularly useful for counting the number of occurrences of items in a large dataset without storing all the items explicitly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:01:25.269777Z",
     "start_time": "2025-05-16T18:01:25.192012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.time.LocalDateTime\n",
    "\n",
    "fun createCountMinSketch(): String {\n",
    "    val windowBucket = LocalDateTime.now().withSecond(0).withNano(0)\n",
    "    try {\n",
    "        jedis.cmsInitByDim(\"topics-cms:$windowBucket\", 3000, 10)\n",
    "    } catch (e: JedisDataException) {\n",
    "        println(\"Count-min sketch already exists\")\n",
    "    }\n",
    "\n",
    "    return \"topics-cms:$windowBucket\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Extraction Handler\n",
    "This function creates a handler that extracts topics from an event's text and stores them in Redis. The topics are stored as a pipe-separated string in the \"topics\" field of the event's hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:01:50.003607Z",
     "start_time": "2025-05-16T18:01:49.914668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val extractTopics: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    val existingTopics = jedis.smembers(\"topics\")\n",
    "    val topics = topicModeling(event.text, existingTopics.joinToString(\", \"))\n",
    "        .replace(\"\\\"\", \"\")\n",
    "        .replace(\"“\", \"\")\n",
    "        .replace(\"”\", \"\")\n",
    "        .split(\",\")\n",
    "        .map { it.trim() }\n",
    "\n",
    "    val cmsKey = createCountMinSketch()\n",
    "    val multi = jedis.multi()\n",
    "    multi.cmsIncrBy(cmsKey, topics.associate { it to 1L })\n",
    "    multi.hset(\"post:\" + event.uri, mapOf(\"topics\" to topics.joinToString(\"|\")))\n",
    "    multi.sadd(\"topics\", *topics.toTypedArray())\n",
    "    multi.exec()\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:01:52.796854Z",
     "start_time": "2025-05-16T18:01:52.763705Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"filtered-events\", \"topic-extraction-example\")",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:05.475503Z",
     "start_time": "2025-05-16T18:02:05.447736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"topic-extraction-bf\"\n",
    "createBloomFilter(bloomFilterName)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:08:45.883346Z",
     "start_time": "2025-05-16T18:08:39.326115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"filtered-events\",\n",
    "        consumerGroup = \"topic-extraction-example\",\n",
    "        consumer = \"topic-extraction-1\",\n",
    "        handlers = listOf(deduplicate(bloomFilterName), printUri, extractTopics),\n",
    "        ackFunction = ackAndBfFn(bloomFilterName),\n",
    "        count = 100,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event from at://did:plc:djglyf5epph2tc44lnqsdvfi/app.bsky.feed.post/3lpcmm7wkrc2y\n",
      "Got event from at://did:plc:ug7ad2kiztx2jhpuw2w44sjz/app.bsky.feed.post/3lpcmm6hkqc27\n",
      "Count-min sketch already exists\n",
      "Got event from at://did:plc:ger7kxkktaqoa32b5lawevrb/app.bsky.feed.post/3lpcmlzriy22k\n",
      "Count-min sketch already exists\n",
      "topic-extraction-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Embeddings for Semantic Search\n",
    "In this section, we'll create embeddings for posts. Embeddings are vector representations of text that capture semantic meaning. They allow us to perform semantic search, which is a search based on meaning rather than exact keyword matching.\n",
    "\n",
    "For example, if I search for:\n",
    "\n",
    "\"Redis is a cool db for Python devs\"\n",
    "\n",
    "I can still match:\n",
    "\n",
    "\"Redis is a great database for Python developers\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Embedding Model\n",
    "We'll use the Spring AI Transformers library to create embeddings for posts. This library provides a simple API for creating embeddings using transformer models."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:05:23.990117Z",
     "start_time": "2025-05-18T16:05:23.648950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-transformers:1.0.0-RC1\")\n",
    "@file:DependsOn(\"ai.djl.huggingface:tokenizers:0.33.0\")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:17.015703Z",
     "start_time": "2025-05-16T18:02:16.204630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.transformers.TransformersEmbeddingModel\n",
    "\n",
    "val embeddingModel = TransformersEmbeddingModel()\n",
    "embeddingModel.afterPropertiesSet()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating an Embedding Handler\n",
    "This function creates a handler that generates embeddings for an event's text and stores them in Redis. The embeddings are stored as binary data in the \"textEmbedding\" field of the event's hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:18.161885Z",
     "start_time": "2025-05-16T18:02:18.120843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.lang.Float\n",
    "import java.nio.ByteBuffer\n",
    "import java.nio.ByteOrder\n",
    "\n",
    "fun createEmbedding(input: String): ByteArray {\n",
    "    val embedding = embeddingModel.embed(input)\n",
    "    val embeddingBytes = ByteArray(Float.BYTES * embedding.size)\n",
    "    ByteBuffer.wrap(embeddingBytes).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer().put(embedding)\n",
    "    return embeddingBytes\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:19.939071Z",
     "start_time": "2025-05-16T18:02:19.893493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val createEmbedding: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    val embeddingBytes = createEmbedding(event.text)\n",
    "    jedis.hset((\"post:\" + event.uri).encodeToByteArray(), mapOf(\"textEmbedding\".encodeToByteArray() to embeddingBytes))\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:24.117302Z",
     "start_time": "2025-05-16T18:02:24.091709Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"filtered-events\", \"embedding-example\")",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:02:25.278676Z",
     "start_time": "2025-05-16T18:02:25.255561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"embedding-bf\"\n",
    "createBloomFilter(bloomFilterName)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:09:01.052158Z",
     "start_time": "2025-05-16T18:08:58.923232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"filtered-events\",\n",
    "        consumerGroup = \"embedding-example\",\n",
    "        consumer = \"embedding-1\",\n",
    "        handlers = listOf(deduplicate(bloomFilterName), printUri, createEmbedding),\n",
    "        ackFunction = ackAndBfFn(bloomFilterName),\n",
    "        count = 100,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding-1: Handler stopped processing: at://did:plc:djglyf5epph2tc44lnqsdvfi/app.bsky.feed.post/3lpcmm7wkrc2y already processed\n",
      "embedding-1: Handler stopped processing: at://did:plc:ug7ad2kiztx2jhpuw2w44sjz/app.bsky.feed.post/3lpcmm6hkqc27 already processed\n",
      "embedding-1: Handler stopped processing: at://did:plc:ger7kxkktaqoa32b5lawevrb/app.bsky.feed.post/3lpcmlzriy22k already processed\n",
      "embedding-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Redis Search Index\n",
    "In this section, we'll create a Redis Search index to make the enriched events searchable. Redis Search is a module that adds full-text search capabilities to Redis. It allows us to search for events based on their text, topics, and other fields."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating the Index Schema in Code\n",
    "Now we'll create the index schema in code. We'll use the Jedis client to create the schema and the index.\n",
    "\n",
    "The following schema defines the fields that will be indexed. The schema includes:\n",
    "- Text fields for full-text search\n",
    "- Tag fields for exact matching\n",
    "- Vector fields for semantic search\n",
    "\n",
    "```\n",
    "FT.CREATE postIdx ON HASH PREFIX 1 post: SCHEMA\n",
    "        parentUri     TEXT\n",
    "        topics        TAG SEPARATOR \"|\"\n",
    "        time_us       TEXT\n",
    "        langs         TAG\n",
    "        uri           TEXT\n",
    "        operation     TAG\n",
    "        did           TAG\n",
    "        timeUs        NUMERIC\n",
    "        rkey          TAG\n",
    "        textEmbedding VECTOR HNSW 6\n",
    "            DIM 384\n",
    "            TYPE FLOAT32\n",
    "            DISTANCE_METRIC COSINE\n",
    "        rootUri       TEXT\n",
    "        text          TEXT\n",
    "```"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:06:23.959257Z",
     "start_time": "2025-05-18T16:06:23.872839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.search.IndexDefinition\n",
    "import redis.clients.jedis.search.IndexOptions\n",
    "import redis.clients.jedis.search.Schema\n",
    "import redis.clients.jedis.search.schemafields.VectorField.VectorAlgorithm\n",
    "\n",
    "val schema = Schema()\n",
    "    .addTextField(\"parentUri\", 1.0)\n",
    "    .addTagField(\"topics\", \"|\")\n",
    "    .addTextField(\"time_us\", 1.0)\n",
    "    .addTagField(\"langs\")\n",
    "    .addTextField(\"uri\", 1.0)\n",
    "    .addTagField(\"operation\")\n",
    "    .addTagField(\"did\")\n",
    "    .addNumericField(\"timeUs\")\n",
    "    .addTagField(\"rkey\")\n",
    "    .addHNSWVectorField(\n",
    "        \"textEmbedding\",\n",
    "        mapOf(\n",
    "            \"type\" to \"FLOAT32\",\n",
    "            \"dim\" to \"384\",\n",
    "            \"distance_metric\" to \"COSINE\",\n",
    "        )\n",
    "    )\n",
    "    .addTextField(\"rootUri\", 1.0)\n",
    "    .addTextField(\"text\", 1.0)\n",
    "\n",
    "// Define index options (e.g., prefix)\n",
    "val rule = IndexDefinition()\n",
    "    .setPrefixes(\"post:\")\n",
    "\n",
    "// Create the index\n",
    "try {\n",
    "    jedis.ftCreate(\"postIdx\", IndexOptions.defaultOptions().setDefinition(rule), schema)\n",
    "} catch (e: JedisDataException) {\n",
    "    println(\"Index already exists\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Searching the Index\n",
    "Now that we have created the index, we can search for events based on their topics, text, and other fields. In this example, we'll search for events with the topic \"Samba\".\n",
    "\n",
    "Redis Search uses a query language similar to SQL. For example, to search for events with the topic \"machine_learning\", we would use the query `@topics:{machine_learning}`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exact Matching Search"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:40:19.391403Z",
     "start_time": "2025-05-16T18:40:19.353851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//FT.SEARCH postIdx \"@topics:{machine_learning}\"\n",
    "val result = jedis.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@topics:{Samba}\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(Event.fromMap(post))\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Full Text Search"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:40:21.265288Z",
     "start_time": "2025-05-16T18:40:21.230146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//FT.SEARCH postIdx \"@text:Open source\"\n",
    "val result = jedis.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@text:Open source\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(Event.fromMap(post))\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vector Similarity Search"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:40:23.490819Z",
     "start_time": "2025-05-16T18:40:23.429833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.search.FTSearchParams\n",
    "import redis.clients.jedis.search.Query\n",
    "\n",
    "val vector: ByteArray = createEmbedding(\"How did they do multiligual TTS?\")\n",
    "\n",
    "val queryString = (\"* =>[KNN \\$K @textEmbedding \\$BLOB AS similarityScore]\")\n",
    "\n",
    "val params = mapOf(\"BLOB\" to vector)\n",
    "\n",
    "var query = Query(queryString)\n",
    "    .addParam(\"K\", 1)\n",
    "    .addParam(\"BLOB\", vector)\n",
    "    .returnFields(\"uri\", \"text\", \"similarityScore\")\n",
    "    .setSortBy(\"similarityScore\", true)\n",
    "    .dialect(2)\n",
    "\n",
    "val result = jedis.ftSearch(\n",
    "    \"postIdx\",\n",
    "    query\n",
    ")\n",
    "\n",
    "result.documents.forEach { doc ->\n",
    "    println(Event.fromMap(doc).toString() + \"\\n\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pre filtering"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T18:40:25.427899Z",
     "start_time": "2025-05-16T18:40:25.370235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//FT.SEARCH postIdx \"@text:Open source\" \"@tag:{Samba}\" \"*=>[KNN 1 @textEmbedding $BLOB AS similarityScore]\"\n",
    "val vector: ByteArray = createEmbedding(\"Open source is wizardry stuff\")\n",
    "\n",
    "val queryString = \"@topics:{Samba} =>[KNN \\$K @textEmbedding \\$BLOB AS similarityScore]\"\n",
    "\n",
    "val params = mapOf(\"BLOB\" to vector)\n",
    "\n",
    "var query = Query(queryString)\n",
    "    .addParam(\"K\", 5) // Top 5 results (if enough from pre filtering)\n",
    "    .addParam(\"BLOB\", vector)\n",
    "    .returnFields(\"uri\", \"text\", \"similarityScore\")\n",
    "    .setSortBy(\"similarityScore\", true)\n",
    "    .dialect(2)\n",
    "\n",
    "val result = jedis.ftSearch(\n",
    "    \"postIdx\",\n",
    "    query\n",
    ")\n",
    "\n",
    "println(result.totalResults)\n",
    "result.documents.forEach { doc ->\n",
    "    println(Event.fromMap(doc).toString() + \"\\n\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
