{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Enriching Filtered Events"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll enrich the filtered events from the previous notebook with additional information. We'll use a combination of techniques to enrich the events:\n",
    "\n",
    "1. Topic modeling using a Large Language Model (LLM) to extract topics from the posts\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Topic Modeling with Large Language Models\n",
    "Topic modeling is a technique used to discover abstract topics in a collection of documents. In this notebook, we'll use a Large Language Model to extract topics from posts. This will allow us to categorize posts and make them more searchable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Ollama API Client\n",
    "We'll use the Spring AI Ollama client to interact with the Ollama API.\n",
    "\n",
    "Ollama is a tool that allows us to run large language models locally."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:49:32.375487Z",
     "start_time": "2025-05-23T10:49:32.149688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%use coroutines\n",
    "@file:DependsOn(\"org.springframework.ai:spring-ai-ollama:1.0.0-RC1\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The prompt we'll use for the LLM is designed to extract software-related topics from posts. The prompt includes examples of how to format the output and what types of topics to include."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:03:25.562054Z",
     "start_time": "2025-05-23T11:03:25.534539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val topicModelingSystemPrompt = File(\"resources/topic-extractor-prompt.txt\").readText()"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the Ollama Chat Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:49:51.811091Z",
     "start_time": "2025-05-23T10:49:51.446141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.ollama.OllamaChatModel\n",
    "import org.springframework.ai.ollama.api.OllamaApi\n",
    "import org.springframework.ai.ollama.api.OllamaApi.ChatRequest\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message.Role\n",
    "import org.springframework.ai.ollama.api.OllamaOptions\n",
    "\n",
    "val ollamaApi = OllamaApi.builder()\n",
    "    .baseUrl(\"http://localhost:11434\")\n",
    "    .build()\n",
    "\n",
    "val ollamaOptions = OllamaOptions.builder().model(\"deepseek-coder-v2\").build()\n",
    "\n",
    "val ollamaChatModel = OllamaChatModel.builder()\n",
    "    .ollamaApi(ollamaApi)\n",
    "    .defaultOptions(ollamaOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Modeling Function\n",
    "This function takes a post as input and uses the Ollama API to extract topics from the post. The function returns a string of comma-separated topics."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:03:27.760799Z",
     "start_time": "2025-05-23T11:03:27.722038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.SystemMessage\n",
    "import org.springframework.ai.chat.messages.UserMessage\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "import dev.raphaeldelio.*\n",
    "\n",
    "fun extractTopics(post: String, existingTopics: String): String {\n",
    "    val messages = listOf(\n",
    "        SystemMessage(topicModelingSystemPrompt),\n",
    "        UserMessage(\"Existing topics: $existingTopics\"),\n",
    "        UserMessage(\"Post: $post\")\n",
    "    )\n",
    "\n",
    "    val response = ollamaChatModel.call(Prompt(messages))\n",
    "    return response.result.output.text ?: \"\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:50:32.031464Z",
     "start_time": "2025-05-23T10:50:25.566239Z"
    }
   },
   "cell_type": "code",
   "source": "extractTopics(\"Kotlin is a great programming language for beginners who wants to build Agentic AI apps\", \"\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " \"Kotlin, Programming Languages, AI Applications\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:50:42.497354Z",
     "start_time": "2025-05-23T10:50:42.184623Z"
    }
   },
   "cell_type": "code",
   "source": "extractTopics(\"Brazilian samba is a great music genre for dancing\", \"\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " \"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Counting how many times a topic appears"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Topk is a probabilistic data structure used for counting the number of occurrences of items in a stream. It is particularly useful for counting the number of occurrences of items in a large dataset without storing all the items explicitly."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:52:24.448115Z",
     "start_time": "2025-05-23T10:52:24.401809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.exceptions.JedisDataException\n",
    "import java.time.LocalDateTime\n",
    "\n",
    "fun createTopK(): String {\n",
    "    val windowBucket = LocalDateTime.now().withMinute(0).withSecond(0).withNano(0)\n",
    "    try {\n",
    "        jedisPooled.topkReserve(\"topics-topk:$windowBucket\", 15, 3000, 10, 0.9)\n",
    "    } catch (_: JedisDataException) {\n",
    "        println(\"TopK already exists\")\n",
    "    }\n",
    "\n",
    "    return \"topics-topk:$windowBucket\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Extraction Handler\n",
    "This function creates a handler that extracts topics from an event's text and stores them in Redis. The topics are stored as a pipe-separated string in the \"topics\" field of the event's hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:54:09.526768Z",
     "start_time": "2025-05-23T10:54:09.424018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val extractTopics: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    val existingTopics = jedisPooled.smembers(\"topics\")\n",
    "    val topics = extractTopics(event.text, existingTopics.joinToString(\", \"))\n",
    "        .replace(\"\\\"\", \"\")\n",
    "        .replace(\"“\", \"\")\n",
    "        .replace(\"”\", \"\")\n",
    "        .split(\",\")\n",
    "        .map { it.trim() }\n",
    "        .filter { it.isNotBlank() }\n",
    "\n",
    "    val topKKey = createTopK()\n",
    "    if (topics.isNotEmpty()) {\n",
    "        jedisPooled.topkAdd(topKKey, *topics.toTypedArray())\n",
    "        jedisPooled.hset(\"post:\" + event.uri.replace(\"at://did:plc:\", \"\"), mapOf(\"topics\" to topics.joinToString(\"|\")))\n",
    "        jedisPooled.sadd(\"topics\", *topics.toTypedArray())\n",
    "    }\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:54:11.628267Z",
     "start_time": "2025-05-23T10:54:11.600274Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"filtered-events\", \"topic-extraction-example\")",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:54:44.208572Z",
     "start_time": "2025-05-23T10:54:32.417146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"filtered-events\",\n",
    "        consumerGroup = \"topic-extraction-example\",\n",
    "        consumer = \"topic-extraction-1\",\n",
    "        handlers = listOf(printUri, extractTopics),\n",
    "        ackFunction = ackFn(),\n",
    "        count = 1,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event from at://did:plc:p7ulrp4foqwo3clni7c6le4j/app.bsky.feed.post/3lptgszmsb22e\n",
      "Got event from at://did:plc:rdawdbanqn3rewsoqwwgn64f/app.bsky.feed.post/3lptgtlav2224\n",
      "TopK already exists\n",
      "Got event from at://did:plc:4qx5w4ydgxfqjjulu7iaqcb6/app.bsky.feed.post/3lptgtpegys2g\n",
      "TopK already exists\n",
      "Got event from at://did:plc:4aqdizbvkawdfz3yo4yatync/app.bsky.feed.post/3lptgubcl322e\n",
      "TopK already exists\n",
      "Got event from at://did:plc:qxtnhnigpszcx6hhl3pwzbyk/app.bsky.feed.post/3lptgukodts2z\n",
      "TopK already exists\n",
      "Got event from at://did:plc:zppl6erazdke37t467jo7vru/app.bsky.feed.post/3lptguh54sc2v\n",
      "TopK already exists\n",
      "Got event from at://did:plc:zef4ypw24j2yicvwpkr6pza7/app.bsky.feed.post/3lptguecjf22n\n",
      "TopK already exists\n",
      "Got event from at://did:plc:zef4ypw24j2yicvwpkr6pza7/app.bsky.feed.post/3lptgukn6qc2n\n",
      "TopK already exists\n",
      "Got event from at://did:plc:ajzerqtewuljmsh2ehh7qfqj/app.bsky.feed.post/3lptgunwbzc2t\n",
      "TopK already exists\n",
      "Got event from at://did:plc:2k27drz6ks6t7zlkzdpobwyw/app.bsky.feed.post/3lptguuho7k2z\n",
      "TopK already exists\n",
      "Got event from at://did:plc:7neyvtit7z5yncu2frhd4cn6/app.bsky.feed.post/3lptgv2rn4226\n",
      "TopK already exists\n",
      "Got event from at://did:plc:fgrispfs6gkhxal2fhpomu44/app.bsky.feed.post/3lptgv3mx4s2e\n",
      "TopK already exists\n",
      "Got event from at://did:plc:afozmgsbndsvv62injoqf6qh/app.bsky.feed.post/3lptgvkg6ok2c\n",
      "TopK already exists\n",
      "Got event from at://did:plc:qy6qzwcgt5l4hlepnl76qd2k/app.bsky.feed.post/3lptgvnu7gc2p\n",
      "TopK already exists\n",
      "Got event from at://did:plc:irzyxadjubkulsfoylos3pnt/app.bsky.feed.post/3lptgvnojkc2c\n",
      "TopK already exists\n",
      "Got event from at://did:plc:5xuy5w37n3es62eoywoib3pq/app.bsky.feed.post/3lptgymngyn2p\n",
      "TopK already exists\n",
      "Got event from at://did:plc:bxple4e3h2zxpjkbgptfgexk/app.bsky.feed.post/3lptgyxuynt2z\n",
      "TopK already exists\n",
      "Got event from at://did:plc:ktak3bmjiqror5jkl2fl6lcr/app.bsky.feed.post/3lptgz5picc2p\n",
      "TopK already exists\n",
      "Got event from at://did:plc:aekikn7ngfej4tstgo445op2/app.bsky.feed.post/3lptgz7i4sc2h\n",
      "TopK already exists\n",
      "Got event from at://did:plc:voo45zd6evhndgvo5lbk3etp/app.bsky.feed.post/3lptgzeapql2x\n",
      "TopK already exists\n",
      "Got event from at://did:plc:voo45zd6evhndgvo5lbk3etp/app.bsky.feed.post/3lptgzoicew26\n",
      "TopK already exists\n",
      "Got event from at://did:plc:ou6myafqmpeqjev6spkuympo/app.bsky.feed.post/3lptgztng7k2n\n",
      "TopK already exists\n",
      "Got event from at://did:plc:n6qp5435lelmqnf4q7rqevqt/app.bsky.feed.post/3lptgzxzphs2k\n",
      "TopK already exists\n",
      "Got event from at://did:plc:anakl32s5jly3uumdsoioyoj/app.bsky.feed.post/3lptgzz7t722k\n",
      "TopK already exists\n",
      "Got event from at://did:plc:zy7cgdaiplv6lpoinrvzmqs6/app.bsky.feed.post/3lpthc4le5s2j\n",
      "TopK already exists\n",
      "Got event from at://did:plc:m6hcxzysyuyu4btrcrybpyxi/app.bsky.feed.post/3lpthccf6h22k\n",
      "TopK already exists\n",
      "Got event from at://did:plc:v7j6tlcesyazxyccz3s2ju63/app.bsky.feed.post/3lpthcj2epk2m\n",
      "TopK already exists\n",
      "Got event from at://did:plc:i53e6y3liw2oaw4s6e6odw5m/app.bsky.feed.post/3lpthclhroo2c\n",
      "TopK already exists\n",
      "topic-extraction-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Redis Search Index\n",
    "In this section, we'll create a Redis Search index to make the enriched events searchable. Redis Search is a module that adds full-text search capabilities to Redis. It allows us to search for events based on their text, topics, and other fields."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating the Index Schema in Code\n",
    "Now we'll create the index schema in code. We'll use the Jedis client to create the schema and the index.\n",
    "\n",
    "The following schema defines the fields that will be indexed. The schema includes:\n",
    "- Text fields for full-text search\n",
    "- Tag fields for exact matching\n",
    "- Vector fields for semantic search\n",
    "\n",
    "```\n",
    "FT.CREATE postIdx ON HASH PREFIX 1 post: SCHEMA\n",
    "        parentUri     TEXT\n",
    "        topics        TAG SEPARATOR \"|\"\n",
    "        time_us       TEXT\n",
    "        langs         TAG\n",
    "        uri           TEXT\n",
    "        operation     TAG\n",
    "        did           TAG\n",
    "        timeUs        NUMERIC\n",
    "        rkey          TAG\n",
    "        rootUri       TEXT\n",
    "        text          TEXT\n",
    "```"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:55:38.746065Z",
     "start_time": "2025-05-23T10:55:38.674435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.search.IndexDefinition\n",
    "import redis.clients.jedis.search.IndexOptions\n",
    "import redis.clients.jedis.search.Schema\n",
    "import redis.clients.jedis.search.schemafields.VectorField.VectorAlgorithm\n",
    "\n",
    "val schema = Schema()\n",
    "    .addTextField(\"parentUri\", 1.0)\n",
    "    .addTagField(\"topics\", \"|\")\n",
    "    .addTextField(\"time_us\", 1.0)\n",
    "    .addTagField(\"langs\")\n",
    "    .addTextField(\"uri\", 1.0)\n",
    "    .addTagField(\"operation\")\n",
    "    .addTagField(\"did\")\n",
    "    .addNumericField(\"timeUs\")\n",
    "    .addTagField(\"rkey\")\n",
    "    .addTextField(\"rootUri\", 1.0)\n",
    "    .addTextField(\"text\", 1.0)\n",
    "\n",
    "// Define index options (e.g., prefix)\n",
    "val rule = IndexDefinition()\n",
    "    .setPrefixes(\"post:\")\n",
    "\n",
    "// Create the index\n",
    "try {\n",
    "    jedisPooled.ftCreate(\"postIdx\", IndexOptions.defaultOptions().setDefinition(rule), schema)\n",
    "} catch (e: JedisDataException) {\n",
    "    println(\"Index already exists\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Searching the Index\n",
    "Now that we have created the index, we can search for events based on their topics, text, and other fields. In this example, we'll search for events with the topic \"Samba\".\n",
    "\n",
    "Redis Search uses a query language similar to SQL. For example, to search for events with the topic \"machine_learning\", we would use the query `@topics:{machine_learning}`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exact Matching Search"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:49:07.056523Z",
     "start_time": "2025-05-23T11:49:07.010318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//FT.SEARCH postIdx \"@topics:{machine_learning}\"\n",
    "val result = jedisPooled.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@topics:{OpenAI}\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(post.get(\"topics\"))\n",
    "    println(post.get(\"text\"))\n",
    "    println(\"\\n\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Full Text Search"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:48:48.021340Z",
     "start_time": "2025-05-23T11:48:47.961469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//FT.SEARCH postIdx \"@text:Open source\"\n",
    "val result = jedisPooled.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@text:from general robots\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(post.get(\"text\"))\n",
    "    println(\"\\n\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I should develop some weird technology again, it’s been a bit… \n",
      "\n",
      "aside from general robots, androids, the colony ships, gene splicing and etc, there’s Maxwellian Energy, AIRs/AIRtanks, Bullet Colonies, AS (Artificial Soul)s… I should think of more wacky fake science terms too\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Querying the TopK"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:48:07.415751Z",
     "start_time": "2025-05-23T11:48:06.951877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.ScanParams\n",
    "\n",
    "val jedisScanFn = { cursor: String ->\n",
    "    jedisPooled.scan(cursor, ScanParams().match(\"topics-topk:*\"), \"TopK-TYPE\")\n",
    "}\n",
    "\n",
    "val keys = mutableListOf<String>()\n",
    "var lastCursor = \"0\"\n",
    "do {\n",
    "    val result = jedisScanFn.invoke(lastCursor)\n",
    "    lastCursor = result.cursor\n",
    "    keys.addAll(result.result)\n",
    "} while (lastCursor != \"0\")\n",
    "\n",
    "keys.forEach {\n",
    "    println(it)\n",
    "    val count = jedisPooled.topkListWithCount(it)\n",
    "    println(count)\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics-topk:2025-05-23T12:00\n",
      "{AI=25, Generative Models=21, Machine Learning=18, Prompt Engineering=12, Artificial Intelligence=10, AI Data Security=5, OpenAI=5, Text-to-Image=3, Long-Term Strategy=2, Writing Tools=2, Mathematics=2, History=1, Wave Equations=1, Infinite Energy Hunger=1, Commercial Dependency=1}\n",
      "topics-topk:2025-05-23T13:00\n",
      "{Generative Models=6, Prompt Engineering=4, AI=4, OpenAI=2, AI Tooling=2, Azure Cloud=1, HPC=1, Web Application Development=1, Supercomputers=1, AI Model=1}\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false,
   "projectDependencies": [
    "kotlinconf-bsky-bot.kotlin-notebooks.main"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
