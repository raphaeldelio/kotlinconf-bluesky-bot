{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Filtering JetStream Events"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll filter events from the Redis Stream that we created in the previous notebook. We'll use a combination of techniques to filter the events:\n",
    "\n",
    "1. Deduplication using Redis Bloom Filter to avoid processing the same event multiple times\n",
    "2. Content-based filtering using a machine learning model to identify software-related posts\n",
    "3. Storing filtered events in Redis for further processing\n",
    "\n",
    "Redis Bloom Filter is a probabilistic data structure that allows us to check if an element is in a set. It's very memory efficient and has a constant time complexity for both insertion and lookup operations. The trade-off is that it can have false positives, but the probability of false positives can be controlled by the size of the filter.\n",
    "\n",
    "Machine learning models can be used to classify text into different categories. In this notebook, we'll use a pre-trained zero-shot classification model to classify posts as software-related or not."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Consuming from Redis Streams"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model Redis Streams Event\n",
    "In this section, we'll define a data class to represent the events stored in the Redis Stream. This model will be used to deserialize the events from the stream."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:13.311171Z",
     "start_time": "2025-05-19T12:39:12.991749Z"
    }
   },
   "cell_type": "code",
   "source": "@file:DependsOn(\"redis.clients:jedis:6.0.0\")",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:13.839513Z",
     "start_time": "2025-05-19T12:39:13.319075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.resps.StreamEntry\n",
    "\n",
    "data class Event(\n",
    "    val did: String,\n",
    "    val rkey: String,\n",
    "    val text: String,\n",
    "    val timeUs: String,\n",
    "    val operation: String,\n",
    "    val uri: String,\n",
    "    val parentUri: String,\n",
    "    val rootUri: String,\n",
    "    val langs: List<String>,\n",
    ") {\n",
    "    companion object {\n",
    "        fun fromMap(entry: StreamEntry): Event {\n",
    "            val fields = entry.fields\n",
    "            return Event(\n",
    "                did = fields[\"did\"] ?: \"\",\n",
    "                rkey = fields[\"rkey\"] ?: \"\",\n",
    "                text = fields[\"text\"] ?: \"\",\n",
    "                timeUs = fields[\"timeUs\"] ?: \"\",\n",
    "                operation = fields[\"operation\"] ?: \"\",\n",
    "                uri = fields[\"uri\"] ?: \"\",\n",
    "                parentUri = fields[\"parentUri\"] ?: \"\",\n",
    "                rootUri = fields[\"rootUri\"] ?: \"\",\n",
    "                langs = fields[\"langs\"]?.replace(\"[\", \"\")?.replace(\"]\", \"\")?.split(\", \") ?: emptyList()\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Redis Client\n",
    "Create a Jedis client to connect to Redis. This is a reusable client that can be used to interact with Redis Streams."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.135933Z",
     "start_time": "2025-05-19T12:39:13.872678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.JedisPooled\n",
    "\n",
    "val jedisPooled = JedisPooled()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Consumer Group\n",
    "Create a consumer group to read from the Redis Stream. A consumer group allows multiple consumers to read from the same stream without duplicating the work. Each consumer in the group will receive a different subset of the messages.\n",
    "\n",
    "A consumer group can be created in Redis with the XGROUP CREATE command:\n",
    "\n",
    "`XGROUP CREATE streamName groupName id [MKSTREAM]`\n",
    "\n",
    "To create a consumer group in this notebook, we will encapsulate the command in a function. The function will take the stream name and the group name as parameters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.247637Z",
     "start_time": "2025-05-19T12:39:14.142946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.StreamEntryID\n",
    "\n",
    "fun createConsumerGroup(streamName: String, consumerGroupName: String) {\n",
    "    try {\n",
    "        jedisPooled.xgroupCreate(streamName, consumerGroupName, StreamEntryID(\"0-0\"), true)\n",
    "    } catch (_: Exception) {\n",
    "        println(\"Group already exists\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.291125Z",
     "start_time": "2025-05-19T12:39:14.254167Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"jetstream\", \"printer-example\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group already exists\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reading from the Stream\n",
    "Create a reusable function to read from the stream. This function will read from the stream and return a list of entries. It uses the XREADGROUP command to read from the stream as part of a consumer group:\n",
    "\n",
    "`XREADGROUP GROUP groupName consumerName COUNT count BLOCK blockTime streamName id`\n",
    "\n",
    "The command will be encapsulated in a function that takes the stream name, consumer group name, consumer name, and count as parameters. The function will return a list of entries."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.415826Z",
     "start_time": "2025-05-19T12:39:14.296279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.XReadGroupParams\n",
    "\n",
    "fun readFromStream(\n",
    "    streamName: String,\n",
    "    consumerGroup: String,\n",
    "    consumer: String, count: Int\n",
    "): List<Map.Entry<String, List<StreamEntry>>> {\n",
    "    return jedisPooled.xreadGroup(\n",
    "        consumerGroup,\n",
    "        consumer,\n",
    "        XReadGroupParams().count(count),\n",
    "        mapOf(\n",
    "            streamName to StreamEntryID.XREADGROUP_UNDELIVERED_ENTRY\n",
    "        )\n",
    "    ) ?: emptyList()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Acknowledging Messages\n",
    "Create a function to acknowledge the message. This is important to let Redis know that the message has been processed successfully, so it won't be delivered to other consumers in the group.\n",
    "\n",
    "This is done by using the XACK command:\n",
    "\n",
    "`XACK streamName groupName id`\n",
    "\n",
    "The command will be encapsulated in a lambda function that takes the stream name, consumer group name, and entry as parameters. The function will acknowledge the message by calling the XACK command."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.486575Z",
     "start_time": "2025-05-19T12:39:14.420550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun ackFunction(): (String, String, StreamEntry) -> Unit {\n",
    "    return { streamName, consumerGroup, entry ->\n",
    "        jedisPooled.xack(\n",
    "            streamName,\n",
    "            consumerGroup,\n",
    "            entry.id\n",
    "        )\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Consuming the Stream\n",
    "Create a reusable function to consume the stream.\n",
    "\n",
    "This function implements a pipeline pattern where each event is processed sequentially by a series of handlers. If any handler returns false, the processing stops for that event.\n",
    "\n",
    "After processing the event, the function acknowledges the message using the ack function."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.583391Z",
     "start_time": "2025-05-19T12:39:14.490728Z"
    }
   },
   "cell_type": "code",
   "source": "%use coroutines",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.847314Z",
     "start_time": "2025-05-19T12:39:14.589564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlinx.coroutines.*\n",
    "\n",
    "fun consumeStream(\n",
    "    streamName: String,\n",
    "    consumerGroup: String,\n",
    "    consumer: String,\n",
    "    handlers: List<(Event) -> Pair<Boolean, String>>,\n",
    "    ackFunction: ((String, String, StreamEntry) -> Unit),\n",
    "    count: Int = 5,\n",
    "    limit: Int = 5\n",
    ") {\n",
    "    var lastMessageTime = System.currentTimeMillis()\n",
    "    var consumed = 0\n",
    "\n",
    "    while (consumed < limit) {\n",
    "        val entries = readFromStream(streamName, consumerGroup, consumer, count)\n",
    "        val allEntries = entries.flatMap { it.value }\n",
    "        allEntries.map { entry ->\n",
    "            consumed++\n",
    "            val event = Event.fromMap(entry)\n",
    "\n",
    "            for (handler in handlers) {\n",
    "                val (shouldContinue, message) = handler(event)\n",
    "                ackFunction(streamName, consumerGroup, entry)\n",
    "\n",
    "                if (!shouldContinue) {\n",
    "                    println(\"$consumer: Handler stopped processing: $message\")\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (allEntries.isEmpty()) {\n",
    "            val now = System.currentTimeMillis()\n",
    "            if (now - lastMessageTime >= 2_000) {\n",
    "                println(\"$consumer: No new messages for 2 seconds. Stopping.\")\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To test the consumeStream function, we'll create a simple handler that prints the event's URI."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:14.932815Z",
     "start_time": "2025-05-19T12:39:14.855857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val printUri: (Event) -> Pair<Boolean, String> = {\n",
    "    println(\"Got event from ${it.uri}\")\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.071881Z",
     "start_time": "2025-05-19T12:39:14.940204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"jetstream\",\n",
    "        consumerGroup = \"printer-example\",\n",
    "        consumer =\"printer-1\",\n",
    "        handlers = listOf(printUri),\n",
    "        ackFunction = ackFunction(),\n",
    "        count = 100,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printer-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Deduplication with Bloom Filter\n",
    "Redis Bloom Filter is a probabilistic data structure that allows us to check if an element is in a set. It's very memory efficient and has a constant time complexity for both insertion and lookup operations.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Bloom Filter\n",
    "This function creates a Bloom Filter with the given name. The filter is configured with an error rate of 0.01 and an initial capacity of 1,000,000 elements."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.111118Z",
     "start_time": "2025-05-19T12:39:17.077376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.bloom.BFReserveParams\n",
    "import redis.clients.jedis.exceptions.JedisDataException\n",
    "fun createBloomFilter(name: String) {\n",
    "    try {\n",
    "        val errorRate = 0.01\n",
    "        val capacity = 1_000_000L\n",
    "        val reserveParams = BFReserveParams().expansion(2)\n",
    "        jedisPooled.bfReserve(name, errorRate, capacity, reserveParams)\n",
    "    } catch (_: JedisDataException) {\n",
    "        println(\"Bloom filter already exists\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Deduplication Handler\n",
    "This function creates a handler that checks if an event has already been processed by checking if its URI is in the Bloom Filter. If the URI is in the filter, the handler returns false, which stops the processing of the event.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.150207Z",
     "start_time": "2025-05-19T12:39:17.113651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun deduplicate(bloomFilter: String): (Event) -> Pair<Boolean, String> {\n",
    "    return { event ->\n",
    "        if (jedisPooled.bfExists(bloomFilter, event.uri)) {\n",
    "            Pair(false, \"${event.uri} already processed\")\n",
    "        } else {\n",
    "            Pair(true, \"OK\")\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Atomic Acknowledgment and Bloom Filter Update\n",
    "This function creates a handler that acknowledges the message and adds the URI to the Bloom Filter in a single atomic transaction. This ensures that if the acknowledgment succeeds, the URI is also added to the filter, and vice versa.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.249918Z",
     "start_time": "2025-05-19T12:39:17.157198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.Connection\n",
    "import redis.clients.jedis.JedisPool\n",
    "import redis.clients.jedis.Transaction\n",
    "\n",
    "val jedisPool = JedisPool()\n",
    "\n",
    "fun ackAndBfFn(bloomFilter: String):  (String, String, StreamEntry) -> Unit {\n",
    "    return { streamName, consumerGroup, entry ->\n",
    "        jedisPool.resource.use { jedis ->\n",
    "            // Create a transaction\n",
    "            val multi = jedis.multi()\n",
    "\n",
    "            // Acknowledge the message\n",
    "            multi.xack(\n",
    "                streamName,\n",
    "                consumerGroup,\n",
    "                entry.id\n",
    "            )\n",
    "\n",
    "            // Add the URI to the bloom filter\n",
    "            multi.bfAdd(bloomFilter, Event.fromMap(entry).uri)\n",
    "\n",
    "            // Execute the transaction\n",
    "            multi.exec()\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.277222Z",
     "start_time": "2025-05-19T12:39:17.255569Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"jetstream\", \"deduplicate-example\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group already exists\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:17.314162Z",
     "start_time": "2025-05-19T12:39:17.284964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"processed-uris\"\n",
    "createBloomFilter(\"processed-uris\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom filter already exists\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:19.400715Z",
     "start_time": "2025-05-19T12:39:17.323417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"jetstream\",\n",
    "        consumerGroup = \"deduplicate-example\",\n",
    "        consumer = \"deduplicate-1\",\n",
    "        handlers = listOf(deduplicate(bloomFilterName), printUri),\n",
    "        ackFunction = ackAndBfFn(bloomFilterName),\n",
    "        count = 100,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplicate-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Content-Based Filtering with Machine Learning\n",
    "In this section, we'll use a machine learning model to filter posts based on their content. We'll use a pre-trained zero-shot classification model to classify posts as software-related or not."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Machine Learning Model\n",
    "To load the model, we'll use the DJL (Deep Java Library) library. DJL is a high-level framework for deep learning in Java that provides a simple and consistent API for loading and using models."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:19.501940Z",
     "start_time": "2025-05-19T12:39:19.413386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"ai.djl.huggingface:tokenizers:0.33.0\")\n",
    "@file:DependsOn(\"ai.djl.pytorch:pytorch-engine:0.33.0\")\n",
    "@file:DependsOn(\"ai.djl:api:0.33.0\")\n",
    "@file:DependsOn(\"ai.djl:model-zoo:0.33.0\")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating the Model Criteria\n",
    "The criteria is used to load the model and create a predictor. The criteria specifies the model path, the engine to use (in this case, PyTorch), and the translator to use.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:35.169782Z",
     "start_time": "2025-05-19T12:39:30.745408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer\n",
    "import ai.djl.huggingface.translator.ZeroShotClassificationTranslator\n",
    "import ai.djl.huggingface.translator.ZeroShotClassificationTranslatorFactory\n",
    "import ai.djl.modality.nlp.translator.ZeroShotClassificationInput\n",
    "import ai.djl.modality.nlp.translator.ZeroShotClassificationOutput\n",
    "import ai.djl.repository.zoo.Criteria\n",
    "import dev.raphaeldelio.CustomZeroShotClassificationTranslator\n",
    "import java.nio.file.Paths\n",
    "import kotlin.io.path.listDirectoryEntries\n",
    "\n",
    "val tokenizer = HuggingFaceTokenizer.newInstance(Paths.get(\"/Users/raphaeldelio/Documents/GitHub/redis/kotlinconf-bsky-bot/kotlin-notebooks/notebooks/resources/model/DeBERTa-v3-large-mnli-fever-anli-ling-wanli/tokenizer.json\"))\n",
    "\n",
    "val translator = CustomZeroShotClassificationTranslator.builder(tokenizer).build()\n",
    "\n",
    "val criteria: Criteria<ZeroShotClassificationInput, ZeroShotClassificationOutput> = Criteria.builder()\n",
    "    .setTypes(\n",
    "        ZeroShotClassificationInput::class.java,\n",
    "        ZeroShotClassificationOutput::class.java\n",
    "    )\n",
    "    .optModelPath(Paths.get(\"resources/model/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"))\n",
    "    .optEngine(\"PyTorch\")\n",
    "    .optTranslator(translator)\n",
    "    .build()\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading the Model\n",
    "Now we'll load the model and create a predictor. The predictor is used to make predictions with the model.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:37.046629Z",
     "start_time": "2025-05-19T12:39:36.164658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.djl.repository.zoo.ModelZoo\n",
    "\n",
    "val model = ModelZoo.loadModel(criteria)\n",
    "val predictor = model.newPredictor()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Classification Function\n",
    "Now we'll create a function to classify text using the model.\n",
    "\n",
    "The function takes a text as input and returns a classification output. The classification output contains the probabilities for each candidate label.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:38.682700Z",
     "start_time": "2025-05-19T12:39:38.640105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.djl.modality.nlp.translator.ZeroShotClassificationOutput\n",
    "\n",
    "fun classify(premise: String): ZeroShotClassificationOutput {\n",
    "    val candidateLabels = listOf(\"politics\", \"american politics\", \"european politics\")\n",
    "    val input = ZeroShotClassificationInput(premise, candidateLabels.toTypedArray(), true, \"{}\")\n",
    "    return predictor.predict(input)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Filter Handler\n",
    "Now we'll create a handler that filters events based on their content.\n",
    "\n",
    "The handler uses the classification function to determine if a post is software-related.\n",
    "\n",
    "If the post is not software-related, the handler returns false, which stops the processing of the event.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:39:40.500128Z",
     "start_time": "2025-05-19T12:39:40.425348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val filter: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    if (event.text.isNotBlank() && event.operation != \"delete\") {\n",
    "        val classification = classify(event.text)\n",
    "        if (classification.scores.any { it > 0.90 }) {\n",
    "            Pair(true, \"OK\")\n",
    "        } else {\n",
    "            Pair(false, \"Not a post related to politics\")\n",
    "        }\n",
    "    } else {\n",
    "        Pair(false, \"Text is null or empty\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Storing Filtered Events\n",
    "In this section, we'll store the filtered events in Redis for further processing.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Converting Events to Maps\n",
    "First, we need a function to convert an Event object to a Map that can be stored in Redis as a Hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:15.975990Z",
     "start_time": "2025-05-19T12:40:15.926848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.raphaeldelio.*\n",
    "\n",
    "fun Event.toMap() = mapOf(\n",
    "    \"did\" to this.did,\n",
    "    \"timeUs\" to this.timeUs,\n",
    "    \"text\" to this.text,\n",
    "    \"langs\" to this.langs.joinToString(\"|\"),\n",
    "    \"operation\" to this.operation,\n",
    "    \"rkey\" to this.rkey,\n",
    "    \"parentUri\" to this.parentUri,\n",
    "    \"rootUri\" to this.rootUri,\n",
    "    \"uri\" to this.uri\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Storing Events in Redis\n",
    "Now we'll create a handler that stores events in Redis. The handler stores the event as a hash in Redis, with the key being the event's URI.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:19.553698Z",
     "start_time": "2025-05-19T12:40:19.517845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val storeEvent: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    jedisPooled.hset(\"post:\" + event.uri, event.toMap())\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adding Filtered Events to a New Stream\n",
    "Finally, we'll create a handler that adds filtered events to a new stream. This allows other consumers to process only the filtered events, rather than having to filter the events themselves.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:22.343058Z",
     "start_time": "2025-05-19T12:40:22.304182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.XAddParams\n",
    "\n",
    "val addFilteredEventToStream: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    jedisPooled.xadd(\n",
    "        \"filtered-events\",\n",
    "        XAddParams.xAddParams()\n",
    "            .id(StreamEntryID.NEW_ENTRY)\n",
    "            .maxLen(1_000_000)\n",
    "            .exactTrimming(),\n",
    "        event.toMap()\n",
    "    )\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:24.666859Z",
     "start_time": "2025-05-19T12:40:24.645512Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"jetstream\", \"store-example\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group already exists\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:25.658348Z",
     "start_time": "2025-05-19T12:40:25.634897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"store-bf\"\n",
    "createBloomFilter(bloomFilterName)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom filter already exists\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting It All Together\n",
    "Now we'll put all the pieces together to create a complete pipeline for filtering events from the Redis Stream.\n",
    "\n",
    "In this example we create two consumers that will process the same stream.\n",
    "- By doing that, we can scale the processing of the events by adding more consumers to the group.\n",
    "- Redis will make sure that each consumer will receive different messages.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:40:29.851064Z",
     "start_time": "2025-05-19T12:40:27.747942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "        listOf(\n",
    "            async(Dispatchers.IO) {\n",
    "                consumeStream(\n",
    "                    streamName = \"jetstream\",\n",
    "                    consumerGroup = \"store-example\",\n",
    "                    consumer = \"store-1\",\n",
    "                    handlers = listOf(\n",
    "                        deduplicate(bloomFilterName),\n",
    "                        filter,\n",
    "                        printUri,\n",
    "                        storeEvent,\n",
    "                        addFilteredEventToStream\n",
    "                    ),\n",
    "                    ackFunction = ackAndBfFn(bloomFilterName),\n",
    "                    count = 5,\n",
    "                    limit = 50\n",
    "                )\n",
    "            },\n",
    "            async(Dispatchers.IO) {\n",
    "                consumeStream(\n",
    "                    streamName = \"jetstream\",\n",
    "                    consumerGroup = \"store-example\",\n",
    "                    consumer = \"store-2\", // Different consumer\n",
    "                    handlers = listOf(\n",
    "                        deduplicate(bloomFilterName),\n",
    "                        filter,\n",
    "                        printUri,\n",
    "                        storeEvent,\n",
    "                        addFilteredEventToStream\n",
    "                    ),\n",
    "                    ackFunction = ackAndBfFn(bloomFilterName),\n",
    "                    count = 5,\n",
    "                    limit = 50\n",
    "                )\n",
    "            }\n",
    "        ).awaitAll()\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store-1: No new messages for 2 seconds. Stopping.\n",
      "store-2: No new messages for 2 seconds. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[kotlin.Unit, kotlin.Unit]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "In the next notebook, we'll enrich the filtered events with additional information, such as topic modeling and embeddings for semantic search.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false,
   "projectDependencies": [
    "kotlinconf-bsky-bot.kotlin-notebooks.main"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
